{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gogamid/ml-notebooks/blob/main/continualai/05_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "jD2kbFHY_ijW"
      },
      "source": [
        "---\n",
        "description: Automatic Evaluation with Pre-implemented Metrics\n",
        "---\n",
        "\n",
        "# Evaluation\n",
        "\n",
        "Welcome to the \"_Evaluation_\" tutorial of the \"_From Zero to Hero_\" series. In this part we will present the functionalities offered by the `evaluation` module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3vTdDxgy_ijY",
        "outputId": "b00c58dd-b850-4ed4-d665-1e014829d18f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting avalanche-lib==0.4\n",
            "  Downloading avalanche_lib-0.4.0-py3-none-any.whl (894 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m894.6/894.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions==4.4.0 (from avalanche-lib==0.4)\n",
            "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.4) (5.9.5)\n",
            "Collecting gputil (from avalanche-lib==0.4)\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.4) (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.4) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.4) (1.23.5)\n",
            "Collecting pytorchcv (from avalanche-lib==0.4)\n",
            "  Downloading pytorchcv-0.0.67-py2.py3-none-any.whl (532 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m532.4/532.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb (from avalanche-lib==0.4)\n",
            "  Downloading wandb-0.16.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=1.15 in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.4) (2.15.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.4) (4.66.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.4) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.4) (0.16.0+cu121)\n",
            "Collecting torchmetrics (from avalanche-lib==0.4)\n",
            "  Downloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.4) (4.6.6)\n",
            "Collecting quadprog (from avalanche-lib==0.4)\n",
            "  Downloading quadprog-0.1.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m452.8/452.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from avalanche-lib==0.4)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.4) (23.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.4) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.4) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.4) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.4) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.4) (3.5.1)\n",
            "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.4) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.4) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.4) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.4) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.4) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.4) (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown->avalanche-lib==0.4) (3.13.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->avalanche-lib==0.4) (4.11.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->avalanche-lib==0.4) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->avalanche-lib==0.4) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->avalanche-lib==0.4) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->avalanche-lib==0.4) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->avalanche-lib==0.4) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->avalanche-lib==0.4) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->avalanche-lib==0.4) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->avalanche-lib==0.4) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->avalanche-lib==0.4) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->avalanche-lib==0.4) (3.2.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->avalanche-lib==0.4) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->avalanche-lib==0.4) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->avalanche-lib==0.4) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->avalanche-lib==0.4) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->avalanche-lib==0.4) (2.1.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics->avalanche-lib==0.4)\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->avalanche-lib==0.4) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->avalanche-lib==0.4)\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb->avalanche-lib==0.4)\n",
            "  Downloading sentry_sdk-1.39.2-py2.py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->avalanche-lib==0.4)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb->avalanche-lib==0.4) (6.0.1)\n",
            "Collecting setproctitle (from wandb->avalanche-lib==0.4)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->avalanche-lib==0.4) (1.4.4)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->avalanche-lib==0.4)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->avalanche-lib==0.4) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->avalanche-lib==0.4) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->avalanche-lib==0.4) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=1.15->avalanche-lib==0.4) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->avalanche-lib==0.4) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->avalanche-lib==0.4) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->avalanche-lib==0.4) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->avalanche-lib==0.4) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=1.15->avalanche-lib==0.4) (2.1.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->avalanche-lib==0.4) (2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->avalanche-lib==0.4) (1.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->avalanche-lib==0.4) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->avalanche-lib==0.4)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.15->avalanche-lib==0.4) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=1.15->avalanche-lib==0.4) (3.2.2)\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7393 sha256=f06b77a81c34eeb435c1fdf45b5091eb9b5c28aa16a1ccd3cb9dd67c1664ede6\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil, typing-extensions, smmap, setproctitle, sentry-sdk, quadprog, docker-pycreds, dill, pytorchcv, lightning-utilities, gitdb, torchmetrics, GitPython, wandb, avalanche-lib\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "Successfully installed GitPython-3.1.41 avalanche-lib-0.4.0 dill-0.3.7 docker-pycreds-0.4.0 gitdb-4.0.11 gputil-1.4.0 lightning-utilities-0.10.0 pytorchcv-0.0.67 quadprog-0.1.11 sentry-sdk-1.39.2 setproctitle-1.3.3 smmap-5.0.1 torchmetrics-1.2.1 typing-extensions-4.4.0 wandb-0.16.2\n"
          ]
        }
      ],
      "source": [
        "!pip install avalanche-lib==0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1pwTEhL_ijZ"
      },
      "source": [
        "## üìà The Evaluation Module\n",
        "\n",
        "\n",
        "\n",
        "The `evaluation` module is quite straightforward: it offers all the basic functionalities to evaluate and keep track of a continual learning experiment.\n",
        "\n",
        "This is mostly done through the **Metrics**: a set of classes which implement the main continual learning metrics computation like A_ccuracy_, F_orgetting_, M_emory Usage_, R_unning Times_, etc. At the moment, in _Avalanche_ we offer a number of pre-implemented metrics you can use for your own experiments. We made sure to include all the major accuracy-based metrics but also the ones related to computation and memory.\n",
        "\n",
        "Each metric comes with a standalone class and a set of plugin classes aimed at emitting metric values on specific moments during training and evaluation.\n",
        "\n",
        "#### Standalone metric\n",
        "\n",
        "As an example, the standalone `Accuracy` class can be used to monitor the average accuracy over a stream of `<input,target>` pairs. The class provides an `update` method to update the current average accuracy, a `result` method to print the current average accuracy and a `reset` method to set the current average accuracy to zero. The call to `result`does not change the metric state.  \n",
        "\n",
        "The `TaskAwareAccuracy` metric keeps separate accuracy counters for different task labels. As such, it requires the `task_labels` parameter, which specifies which task is associated with the current patterns. The metric returns a dictionary mapping task labels to accuracy values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "DQG7uD46_ijZ",
        "outputId": "ad36b2a9-541f-4dd3-be9d-ac8735feeef6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Accuracy:  0.0\n",
            "Average Accuracy:  0.5\n",
            "Average Accuracy:  0.75\n",
            "Average Accuracy:  0.5\n",
            "After reset:  0.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from avalanche.evaluation.metrics import Accuracy, TaskAwareAccuracy\n",
        "\n",
        "# create an instance of the standalone Accuracy metric\n",
        "# initial accuracy is 0\n",
        "acc_metric = Accuracy()\n",
        "print(\"Initial Accuracy: \", acc_metric.result()) #  output 0.0\n",
        "\n",
        "# two consecutive metric updates\n",
        "real_y = torch.tensor([1, 2]).long()\n",
        "predicted_y = torch.tensor([1, 0]).float()\n",
        "acc_metric.update(real_y, predicted_y)\n",
        "acc = acc_metric.result()\n",
        "print(\"Average Accuracy: \", acc) # output 0.5\n",
        "predicted_y = torch.tensor([1,2]).float()\n",
        "acc_metric.update(real_y, predicted_y)\n",
        "acc = acc_metric.result()\n",
        "print(\"Average Accuracy: \", acc) # output 0.75\n",
        "\n",
        "predicted_y = torch.tensor([0,0]).float()\n",
        "acc_metric.update(real_y, predicted_y)\n",
        "acc = acc_metric.result()\n",
        "print(\"Average Accuracy: \", acc) # output 0.5\n",
        "\n",
        "# reset accuracy\n",
        "acc_metric.reset()\n",
        "print(\"After reset: \", acc_metric.result()) # output 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5BeDffdT_ija",
        "outputId": "f54797cf-8291-48be-b586-6e494c753ee6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Accuracy:  {}\n",
            "Average Accuracy:  {0: 0.5}\n",
            "Average Accuracy:  {0: 0.5, 1: 1.0}\n",
            "Average Accuracy:  {0: 0.75, 1: 1.0}\n",
            "After reset:  {}\n"
          ]
        }
      ],
      "source": [
        "# create an instance of the standalone TaskAwareAccuracy metric\n",
        "# initial accuracy is 0 for each task\n",
        "acc_metric = TaskAwareAccuracy()\n",
        "print(\"Initial Accuracy: \", acc_metric.result()) #  output {}\n",
        "\n",
        "# metric updates for 2 different tasks\n",
        "task_label = 0\n",
        "real_y = torch.tensor([1, 2]).long()\n",
        "predicted_y = torch.tensor([1, 0]).float()\n",
        "acc_metric.update(real_y, predicted_y, task_label)\n",
        "acc = acc_metric.result()\n",
        "print(\"Average Accuracy: \", acc) # output 0.5 for task 0\n",
        "\n",
        "task_label = 1\n",
        "predicted_y = torch.tensor([1,2]).float()\n",
        "acc_metric.update(real_y, predicted_y, task_label)\n",
        "acc = acc_metric.result()\n",
        "print(\"Average Accuracy: \", acc) # output 0.75 for task 0 and 1.0 for task 1\n",
        "\n",
        "task_label = 0\n",
        "predicted_y = torch.tensor([1,2]).float()\n",
        "acc_metric.update(real_y, predicted_y, task_label)\n",
        "acc = acc_metric.result()\n",
        "print(\"Average Accuracy: \", acc) # output 0.75 for task 0 and 1.0 for task 1\n",
        "\n",
        "# reset accuracy\n",
        "acc_metric.reset()\n",
        "print(\"After reset: \", acc_metric.result()) # output {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvFnh6ha_ija"
      },
      "source": [
        "#### Plugin metric\n",
        "\n",
        "If you want to integrate the available metrics automatically in the training and evaluation flow, you can use plugin metrics, like `EpochAccuracy` which logs the accuracy after each training epoch, or `ExperienceAccuracy` which logs the accuracy after each evaluation experience. Each of these metrics emits a **curve** composed by its values at different points in time \\(e.g. on different training epochs\\).  In order to simplify the use of these metrics, we provided utility functions with which you can create different plugin metrics in one shot. The results of these functions can be passed as parameters directly to the `EvaluationPlugin`\\(see below\\).\n",
        "\n",
        "{% hint style=\"info\" %}\n",
        "We recommend to use the helper functions when creating plugin metrics.\n",
        "{% endhint %}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9DJeVoSw_ija"
      },
      "outputs": [],
      "source": [
        "from avalanche.evaluation.metrics import accuracy_metrics, \\\n",
        "    loss_metrics, forgetting_metrics, bwt_metrics,\\\n",
        "    confusion_matrix_metrics, cpu_usage_metrics, \\\n",
        "    disk_usage_metrics, gpu_usage_metrics, MAC_metrics, \\\n",
        "    ram_usage_metrics, timing_metrics\n",
        "\n",
        "# you may pass the result to the EvaluationPlugin\n",
        "metrics = accuracy_metrics(epoch=True, experience=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab3me6By_ija"
      },
      "source": [
        "## üìêEvaluation Plugin\n",
        "\n",
        "The **Evaluation Plugin** is the object in charge of configuring and controlling the evaluation procedure. This object can be passed to a Strategy as a \"special\" plugin through the evaluator attribute.\n",
        "\n",
        "The Evaluation Plugin accepts as inputs the plugin metrics you want to track. In addition, you can add one or more loggers to print the metrics in different ways \\(on file, on standard output, on Tensorboard...\\).\n",
        "\n",
        "It is also recommended to pass to the Evaluation Plugin the benchmark instance used in the experiment. This allows the plugin to check for consistency during metrics computation. For example, the Evaluation Plugin checks that the `strategy.eval` calls are performed on the same stream or sub-stream. Otherwise, same metric could refer to different portions of the stream.  \n",
        "These checks can be configured to raise errors (stopping computation) or only warnings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ff50d12-4dcf-45d9-9202-30e3d47f249e",
        "id": "WbL8IPCPJI9X"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/TensorMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9912422/9912422 [00:00<00:00, 73085887.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.avalanche/data/mnist/TensorMNIST/raw/train-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/TensorMNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/TensorMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28881/28881 [00:00<00:00, 60964113.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.avalanche/data/mnist/TensorMNIST/raw/train-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/TensorMNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/TensorMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1648877/1648877 [00:00<00:00, 25969716.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.avalanche/data/mnist/TensorMNIST/raw/t10k-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/TensorMNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/TensorMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4542/4542 [00:00<00:00, 11483139.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.avalanche/data/mnist/TensorMNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/TensorMNIST/raw\n",
            "\n",
            "Starting experiment...\n",
            "-- >> Start of training phase << --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:03<00:00,  6.90it/s]\n",
            "Epoch 0 ended.\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:01<00:00, 18.88it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9116\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:00<00:00, 20.50it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 21.08it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:01<00:00, 17.04it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:01<00:00, 19.92it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1857\n",
            "-- >> Start of training phase << --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:11<00:00,  4.23it/s]\n",
            "Epoch 0 ended.\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:00<00:00, 43.59it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.8979\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:00<00:00, 43.82it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.8574\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 43.55it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 41.64it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:00<00:00, 43.72it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3429\n",
            "-- >> Start of training phase << --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 72/72 [00:08<00:00,  8.46it/s]\n",
            "Epoch 0 ended.\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:00<00:00, 40.75it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9062\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:00<00:00, 42.75it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.8173\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 41.68it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.8960\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 44.12it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:00<00:00, 42.72it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5154\n",
            "-- >> Start of training phase << --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:10<00:00,  8.77it/s]\n",
            "Epoch 0 ended.\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:00<00:00, 34.77it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9077\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:00<00:00, 41.57it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.8221\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 41.03it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.9166\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 44.14it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.8407\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:00<00:00, 43.47it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.6880\n",
            "-- >> Start of training phase << --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:13<00:00,  9.10it/s]\n",
            "Epoch 0 ended.\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:00<00:00, 42.07it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.8714\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:00<00:00, 43.63it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.8290\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 41.34it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.9136\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 42.97it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.8693\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:00<00:00, 43.28it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9003\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.8776\n"
          ]
        }
      ],
      "source": [
        "# MY SIMPLE CUMULATIVE EXAMPLE with evaluation plugin showing just accuracy\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import SGD\n",
        "from avalanche.benchmarks.classic import SplitMNIST\n",
        "from avalanche.evaluation.metrics import forgetting_metrics, \\\n",
        "accuracy_metrics, loss_metrics, timing_metrics, cpu_usage_metrics, \\\n",
        "confusion_matrix_metrics, disk_usage_metrics\n",
        "from avalanche.models import SimpleMLP\n",
        "from avalanche.logging import InteractiveLogger\n",
        "from avalanche.training.plugins import EvaluationPlugin\n",
        "from avalanche.training import Naive, Cumulative\n",
        "\n",
        "benchmark = SplitMNIST(n_experiences=5)\n",
        "\n",
        "# MODEL CREATION\n",
        "model = SimpleMLP(num_classes=benchmark.n_classes)\n",
        "\n",
        "# DEFINE THE EVALUATION PLUGIN\n",
        "# The evaluation plugin manages the metrics computation.\n",
        "# It takes as argument a list of metrics, collectes their results and returns\n",
        "# them to the strategy it is attached to.\n",
        "\n",
        "eval_plugin = EvaluationPlugin(\n",
        "    accuracy_metrics(minibatch=False, epoch=False, experience=True, stream=True),\n",
        "    loggers=[InteractiveLogger()],\n",
        "    strict_checks=False\n",
        ")\n",
        "\n",
        "# CREATE THE STRATEGY INSTANCE (NAIVE)\n",
        "# you can use naive too\n",
        "cl_strategy = Cumulative(\n",
        "    model, SGD(model.parameters(), lr=0.001, momentum=0.9),\n",
        "    CrossEntropyLoss(), train_mb_size=500, train_epochs=1, eval_mb_size=100,\n",
        "    evaluator=eval_plugin)\n",
        "\n",
        "# TRAINING LOOP\n",
        "print('Starting experiment...')\n",
        "results = []\n",
        "for experience in benchmark.train_stream:\n",
        "    # train returns a dictionary which contains all the metric values\n",
        "    res = cl_strategy.train(experience)\n",
        "    print('Training completed')\n",
        "\n",
        "    print('Computing accuracy on the whole test set')\n",
        "    # test also returns a dictionary which contains all the metric values\n",
        "    results.append(cl_strategy.eval(benchmark.test_stream))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cFcNGwA_ija",
        "outputId": "0b311fac-e444-42c6-9f85-5c8260e4eb5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting experiment...\n",
            "-- >> Start of training phase << --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:02<00:00,  9.95it/s]\n",
            "Epoch 0 ended.\n",
            "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 55555.4482\n",
            "\tDiskUsage_MB/train_phase/train_stream/Task000 = 55555.4482\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1397\n",
            "\tLoss_MB/train_phase/train_stream/Task000 = 0.3706\n",
            "\tTime_Epoch/train_phase/train_stream/Task000 = 2.5126\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7156\n",
            "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8989\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:00<00:00, 36.97it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 95.0770\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 55555.4482\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3139\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9422\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 37.29it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 94.7052\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 55555.4482\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 5.5396\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 38.36it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 97.9404\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 55555.4482\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.6522\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 36.14it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 99.7670\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 55555.4482\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 4.6092\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:00<00:00, 34.12it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 94.0129\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 55555.4482\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 4.4855\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
            "tensor([[  0,   0, 558, 422,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0, 480, 655,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0, 959,  73,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,  45, 965,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0, 702, 280,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0, 197, 695,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0, 859,  99,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0, 451, 577,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0, 311, 663,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0, 405, 604,   0,   0,   0,   0,   0,   0]])\n",
            "\tDiskUsage_Stream/eval_phase/test_stream/Task000 = 55555.4482\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.8939\n",
            "\tStreamForgetting/eval_phase/test_stream = 0.0000\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1924\n",
            "-- >> Start of training phase << --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24/24 [00:03<00:00,  6.94it/s]\n",
            "Epoch 0 ended.\n",
            "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 55555.4482\n",
            "\tDiskUsage_MB/train_phase/train_stream/Task000 = 55555.4482\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1142\n",
            "\tLoss_MB/train_phase/train_stream/Task000 = 0.3648\n",
            "\tTime_Epoch/train_phase/train_stream/Task000 = 3.4570\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4769\n",
            "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9517\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:00<00:00, 33.09it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 94.1811\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 55555.4482\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.9422\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.5678\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 37.68it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 96.1171\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 55555.4482\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3203\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9648\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 38.96it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 101.3375\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 55555.4482\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.5427\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 36.14it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 98.1413\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 55555.4482\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 4.5965\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:00<00:00, 38.15it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 100.0644\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 55555.4482\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 4.3884\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
            "tensor([[   0,    0,    0,    0,    0,    0,  583,    0,  397,    0],\n",
            "        [   0,    0,    0,    0,    0,    0,   13,    0, 1122,    0],\n",
            "        [   0,    0,    0,    0,    0,    0,  595,    0,  437,    0],\n",
            "        [   0,    0,    0,    0,    0,    0,   93,    0,  917,    0],\n",
            "        [   0,    0,    0,    0,    0,    0,  424,    0,  558,    0],\n",
            "        [   0,    0,    0,    0,    0,    0,  130,    0,  762,    0],\n",
            "        [   0,    0,    0,    0,    0,    0,  931,    0,   27,    0],\n",
            "        [   0,    0,    0,    0,    0,    0,  105,    0,  923,    0],\n",
            "        [   0,    0,    0,    0,    0,    0,   41,    0,  933,    0],\n",
            "        [   0,    0,    0,    0,    0,    0,  193,    0,  816,    0]])\n",
            "\tDiskUsage_Stream/eval_phase/test_stream/Task000 = 55555.4482\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.5059\n",
            "\tStreamForgetting/eval_phase/test_stream = 0.9422\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1864\n",
            "-- >> Start of training phase << --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24/24 [00:02<00:00, 10.11it/s]\n",
            "Epoch 0 ended.\n",
            "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 55555.4482\n",
            "\tDiskUsage_MB/train_phase/train_stream/Task000 = 55555.4482\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3675\n",
            "\tLoss_MB/train_phase/train_stream/Task000 = 0.7500\n",
            "\tTime_Epoch/train_phase/train_stream/Task000 = 2.3732\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3473\n",
            "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9194\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:00<00:00, 37.41it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 96.2436\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 55555.4482\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.9422\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.8649\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 32.56it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 96.8008\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 55555.4482\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp001 = 0.5849\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.6350\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3799\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 35.51it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 97.1915\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 55555.4482\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 0.6757\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.9313\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 37.34it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 95.3767\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 55555.4482\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 3.6490\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:00<00:00, 36.57it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 99.6513\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 55555.4482\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 3.4029\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
            "tensor([[   0,    0,    0,    0,    0,  761,   35,  184,    0,    0],\n",
            "        [   0,    0,    0,    0,    0,  219,    1,  869,   46,    0],\n",
            "        [   0,    0,    0,    0,    0,  302,  353,  364,   13,    0],\n",
            "        [   0,    0,    0,    0,    0,  824,   10,  176,    0,    0],\n",
            "        [   0,    0,    0,    0,    0,   63,   27,  892,    0,    0],\n",
            "        [   0,    0,    0,    0,    0,  769,    7,  116,    0,    0],\n",
            "        [   0,    0,    0,    0,    0,  144,  734,   80,    0,    0],\n",
            "        [   0,    0,    0,    0,    0,    6,    0, 1019,    3,    0],\n",
            "        [   0,    0,    0,    0,    0,  585,    1,  388,    0,    0],\n",
            "        [   0,    0,    0,    0,    0,   36,    4,  969,    0,    0]])\n",
            "\tDiskUsage_Stream/eval_phase/test_stream/Task000 = 55555.4482\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.4769\n",
            "\tStreamForgetting/eval_phase/test_stream = 0.7635\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2522\n",
            "-- >> Start of training phase << --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24/24 [00:02<00:00,  9.18it/s]\n",
            "Epoch 0 ended.\n",
            "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 55555.4482\n",
            "\tDiskUsage_MB/train_phase/train_stream/Task000 = 55555.4482\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3303\n",
            "\tLoss_MB/train_phase/train_stream/Task000 = 1.1149\n",
            "\tTime_Epoch/train_phase/train_stream/Task000 = 2.6140\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2363\n",
            "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7869\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:00<00:00, 29.15it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 94.4559\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 55555.4482\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.9422\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.7211\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 28.03it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 92.9076\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 55555.4482\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp001 = 0.8960\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.4403\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0688\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 28.67it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 91.9686\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 55555.4482\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp002 = 0.6958\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.6154\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2354\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 28.89it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 94.5129\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 55555.4482\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9892\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.8187\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:00<00:00, 25.68it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 88.6070\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 55555.4482\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 3.2092\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
            "tensor([[   0,    0,    0,    0,  158,  513,    4,    0,    0,  305],\n",
            "        [   0,    0,    0,    0,  106,  176,    0,    0,    6,  847],\n",
            "        [   0,    0,    0,    0,  321,  316,   78,    0,    0,  317],\n",
            "        [   0,    0,    0,    0,    8,  565,    2,    0,    0,  435],\n",
            "        [   0,    0,    0,    0,  678,    0,    0,    0,    0,  304],\n",
            "        [   0,    0,    0,    0,  120,  452,    1,    0,    0,  319],\n",
            "        [   0,    0,    0,    0,  577,   65,  133,    0,    0,  183],\n",
            "        [   0,    0,    0,    0,   26,    1,    0,    0,    0, 1001],\n",
            "        [   0,    0,    0,    0,   77,  118,    0,    0,    0,  779],\n",
            "        [   0,    0,    0,    0,   55,    1,    1,    0,    0,  952]])\n",
            "\tDiskUsage_Stream/eval_phase/test_stream/Task000 = 55555.4482\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.2129\n",
            "\tStreamForgetting/eval_phase/test_stream = 0.8447\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2215\n",
            "-- >> Start of training phase << --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [00:02<00:00,  9.57it/s]\n",
            "Epoch 0 ended.\n",
            "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 55555.4482\n",
            "\tDiskUsage_MB/train_phase/train_stream/Task000 = 55555.4482\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9482\n",
            "\tLoss_MB/train_phase/train_stream/Task000 = 0.5233\n",
            "\tTime_Epoch/train_phase/train_stream/Task000 = 2.7175\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4225\n",
            "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9939\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:00<00:00, 34.84it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 96.3642\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 55555.4482\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.9422\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.8432\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 37.82it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 95.9337\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 55555.4482\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp001 = 0.9643\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.9186\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0005\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 36.11it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 100.7240\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 55555.4482\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp002 = 0.9313\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.5604\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 22.91it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 68.7649\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 55555.4482\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp003 = 0.1195\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.2500\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.6991\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:00<00:00, 24.05it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 68.9000\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 55555.4482\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.4514\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9962\n",
            "-- >> End of eval phase << --\n",
            "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
            "tensor([[ 976,    3,    0,    0,    0,    0,    0,    0,    0,    1],\n",
            "        [   4, 1131,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [ 494,  468,    0,    0,   54,    0,    5,    0,    0,   11],\n",
            "        [ 611,  329,    0,    0,    2,    1,    0,    0,    0,   67],\n",
            "        [ 106,  110,    0,    0,  723,    0,    0,    0,    0,   43],\n",
            "        [ 742,  123,    0,    0,    7,    0,    0,    0,    0,   20],\n",
            "        [ 692,  138,    0,    0,  126,    0,    1,    0,    0,    1],\n",
            "        [ 147,  155,    0,    0,   11,    0,    0,    0,    0,  715],\n",
            "        [ 475,  426,    0,    0,   14,    0,    0,    0,    0,   59],\n",
            "        [ 208,   85,    0,    0,   47,    0,    0,    0,    0,  669]])\n",
            "\tDiskUsage_Stream/eval_phase/test_stream/Task000 = 55555.4482\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 1.9804\n",
            "\tStreamForgetting/eval_phase/test_stream = 0.7393\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3500\n"
          ]
        }
      ],
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import SGD\n",
        "from avalanche.benchmarks.classic import SplitMNIST\n",
        "from avalanche.evaluation.metrics import forgetting_metrics, \\\n",
        "accuracy_metrics, loss_metrics, timing_metrics, cpu_usage_metrics, \\\n",
        "confusion_matrix_metrics, disk_usage_metrics\n",
        "from avalanche.models import SimpleMLP\n",
        "from avalanche.logging import InteractiveLogger\n",
        "from avalanche.training.plugins import EvaluationPlugin\n",
        "from avalanche.training import Naive\n",
        "\n",
        "benchmark = SplitMNIST(n_experiences=5)\n",
        "\n",
        "# MODEL CREATION\n",
        "model = SimpleMLP(num_classes=benchmark.n_classes)\n",
        "\n",
        "# DEFINE THE EVALUATION PLUGIN\n",
        "# The evaluation plugin manages the metrics computation.\n",
        "# It takes as argument a list of metrics, collectes their results and returns\n",
        "# them to the strategy it is attached to.\n",
        "\n",
        "eval_plugin = EvaluationPlugin(\n",
        "    accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
        "    loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
        "    timing_metrics(epoch=True),\n",
        "    forgetting_metrics(experience=True, stream=True),\n",
        "    cpu_usage_metrics(experience=True),\n",
        "    confusion_matrix_metrics(num_classes=benchmark.n_classes, save_image=False, stream=True),\n",
        "    disk_usage_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
        "    loggers=[InteractiveLogger()],\n",
        "    strict_checks=False\n",
        ")\n",
        "\n",
        "# CREATE THE STRATEGY INSTANCE (NAIVE)\n",
        "cl_strategy = Naive(\n",
        "    model, SGD(model.parameters(), lr=0.001, momentum=0.9),\n",
        "    CrossEntropyLoss(), train_mb_size=500, train_epochs=1, eval_mb_size=100,\n",
        "    evaluator=eval_plugin)\n",
        "\n",
        "# TRAINING LOOP\n",
        "print('Starting experiment...')\n",
        "results = []\n",
        "for experience in benchmark.train_stream:\n",
        "    # train returns a dictionary which contains all the metric values\n",
        "    res = cl_strategy.train(experience)\n",
        "    print('Training completed')\n",
        "\n",
        "    print('Computing accuracy on the whole test set')\n",
        "    # test also returns a dictionary which contains all the metric values\n",
        "    results.append(cl_strategy.eval(benchmark.test_stream))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "qHoMcAJW_ijb"
      },
      "source": [
        "## Implement your own metric\n",
        "\n",
        "To implement a **standalone metric**, you have to subclass `Metric` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "D4cPl4AJ_ijb"
      },
      "outputs": [],
      "source": [
        "from avalanche.evaluation import Metric\n",
        "\n",
        "\n",
        "# a standalone metric implementation\n",
        "class MyStandaloneMetric(Metric[float]):\n",
        "    \"\"\"\n",
        "    This metric will return a `float` value\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize your metric here\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        pass\n",
        "\n",
        "    def update(self):\n",
        "        \"\"\"\n",
        "        Update metric value here\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def result(self, **kwargs) -> float:\n",
        "        \"\"\"\n",
        "        Emit the metric result here\n",
        "        \"\"\"\n",
        "        return 0\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        \"\"\"\n",
        "        Reset your metric here\n",
        "        \"\"\"\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf20xYcJ_ijb"
      },
      "source": [
        " To implement a **plugin metric** you have to subclass `PluginMetric` class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "iMrzAfLS_ijb"
      },
      "outputs": [],
      "source": [
        "from avalanche.evaluation import PluginMetric\n",
        "from avalanche.evaluation.metrics import Accuracy\n",
        "from avalanche.evaluation.metric_results import MetricValue\n",
        "from avalanche.evaluation.metric_utils import get_metric_name\n",
        "\n",
        "\n",
        "class MyPluginMetric(PluginMetric[float]):\n",
        "    \"\"\"\n",
        "    This metric will return a `float` value after\n",
        "    each training epoch\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the metric\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self._accuracy_metric = Accuracy()\n",
        "\n",
        "    def reset(self, **kwargs) -> None:\n",
        "        \"\"\"\n",
        "        Reset the metric\n",
        "        \"\"\"\n",
        "        self._accuracy_metric.reset()\n",
        "\n",
        "    def result(self, **kwargs) -> float:\n",
        "        \"\"\"\n",
        "        Emit the result\n",
        "        \"\"\"\n",
        "        return self._accuracy_metric.result()\n",
        "\n",
        "    def after_training_iteration(self, strategy: 'PluggableStrategy') -> None:\n",
        "        \"\"\"\n",
        "        Update the accuracy metric with the current\n",
        "        predictions and targets\n",
        "        \"\"\"\n",
        "        # task labels defined for each experience\n",
        "        task_labels = strategy.experience.task_labels\n",
        "        if len(task_labels) > 1:\n",
        "            # task labels defined for each pattern\n",
        "            task_labels = strategy.mb_task_id\n",
        "        else:\n",
        "            task_labels = task_labels[0]\n",
        "\n",
        "        self._accuracy_metric.update(strategy.mb_output, strategy.mb_y,\n",
        "                                     task_labels)\n",
        "\n",
        "    def before_training_epoch(self, strategy: 'PluggableStrategy') -> None:\n",
        "        \"\"\"\n",
        "        Reset the accuracy before the epoch begins\n",
        "        \"\"\"\n",
        "        self.reset()\n",
        "\n",
        "    def after_training_epoch(self, strategy: 'PluggableStrategy'):\n",
        "        \"\"\"\n",
        "        Emit the result\n",
        "        \"\"\"\n",
        "        return self._package_result(strategy)\n",
        "\n",
        "\n",
        "    def _package_result(self, strategy):\n",
        "        \"\"\"Taken from `GenericPluginMetric`, check that class out!\"\"\"\n",
        "        metric_value = self.accuracy_metric.result()\n",
        "        add_exp = False\n",
        "        plot_x_position = strategy.clock.train_iterations\n",
        "\n",
        "        if isinstance(metric_value, dict):\n",
        "            metrics = []\n",
        "            for k, v in metric_value.items():\n",
        "                metric_name = get_metric_name(\n",
        "                    self, strategy, add_experience=add_exp, add_task=k)\n",
        "                metrics.append(MetricValue(self, metric_name, v,\n",
        "                                           plot_x_position))\n",
        "            return metrics\n",
        "        else:\n",
        "            metric_name = get_metric_name(self, strategy,\n",
        "                                          add_experience=add_exp,\n",
        "                                          add_task=True)\n",
        "            return [MetricValue(self, metric_name, metric_value,\n",
        "                                plot_x_position)]\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"\n",
        "        Here you can specify the name of your metric\n",
        "        \"\"\"\n",
        "        return \"Top1_Acc_Epoch\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkX0vLC__ijb"
      },
      "source": [
        "## Accessing metric values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hmG6hn__ijb"
      },
      "source": [
        "If you want to access all the metrics computed during training and evaluation, you have to make sure that `collect_all=True` is set when creating the `EvaluationPlugin` (default option is `True`). This option maintains an updated version of all metric results in the plugin, which can be retrieved by calling `evaluation_plugin.get_all_metrics()`. You can call this methods whenever you need the metrics.\n",
        "\n",
        "The result is a dictionary with full metric names as keys and a tuple of two lists as values. The first list stores all the `x` values recorded for that metric. Each `x` value represents the time step at which the corresponding metric value has been computed. The second list stores metric values associated to the corresponding `x` value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bMqjyFY7_ijb",
        "outputId": "47d32c54-905f-4320-975d-38c457705f11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<function _init_metrics_list_lambda at 0x7853d9053880>, {})\n"
          ]
        }
      ],
      "source": [
        "eval_plugin2 = EvaluationPlugin(\n",
        "    accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
        "    loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
        "    forgetting_metrics(experience=True, stream=True),\n",
        "    timing_metrics(epoch=True),\n",
        "    cpu_usage_metrics(experience=True),\n",
        "    confusion_matrix_metrics(num_classes=benchmark.n_classes, save_image=False, stream=True),\n",
        "    disk_usage_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
        "    collect_all=True, # this is default value anyway\n",
        "    loggers=[InteractiveLogger()]\n",
        ")\n",
        "\n",
        "# since no training and evaluation has been performed, this will return an empty dict.\n",
        "metric_dict = eval_plugin2.get_all_metrics()\n",
        "print(metric_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9qWRfzwi_ijb",
        "outputId": "e9631110-5595-48f7-c9c1-ad48d8a3ee36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([25, 49, 73, 97, 123],\n",
              " [0.7156092315327984,\n",
              "  0.47693092021412187,\n",
              "  0.34733869587540644,\n",
              "  0.23628190993130355,\n",
              "  0.42250296091591])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "d = eval_plugin.get_all_metrics()\n",
        "d['Top1_Acc_Epoch/train_phase/train_stream/Task000']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8y10JTD_ijc"
      },
      "source": [
        "Alternatively, the `train` and `eval` method of every `strategy` returns a dictionary storing, for each metric, the last value recorded for that metric. You can use these dictionaries to incrementally accumulate metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cdbNZKFM_ijc",
        "outputId": "e210b72d-f588-49d9-f650-63f325511472",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Top1_Acc_MB/train_phase/train_stream/Task000': 0.9939393939393939, 'Loss_MB/train_phase/train_stream/Task000': 0.5233470797538757, 'DiskUsage_MB/train_phase/train_stream/Task000': 55555.4482421875, 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.42250296091591, 'Loss_Epoch/train_phase/train_stream/Task000': 1.9481726124547378, 'Time_Epoch/train_phase/train_stream/Task000': 2.7174827160000063, 'DiskUsage_Epoch/train_phase/train_stream/Task000': 55555.4482421875, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.0, 'Loss_Exp/eval_phase/test_stream/Task000/Exp000': 2.7210617399355805, 'CPUUsage_Exp/eval_phase/test_stream/Task000/Exp000': 94.45590309456857, 'DiskUsage_Exp/eval_phase/test_stream/Task000/Exp000': 55555.4482421875, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.06884057971014493, 'Loss_Exp/eval_phase/test_stream/Task000/Exp001': 2.4402871679815448, 'CPUUsage_Exp/eval_phase/test_stream/Task000/Exp001': 92.90756259760283, 'DiskUsage_Exp/eval_phase/test_stream/Task000/Exp001': 55555.4482421875, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002': 0.23541666666666666, 'Loss_Exp/eval_phase/test_stream/Task000/Exp002': 1.6153626429537933, 'CPUUsage_Exp/eval_phase/test_stream/Task000/Exp002': 91.96855434104191, 'DiskUsage_Exp/eval_phase/test_stream/Task000/Exp002': 55555.4482421875, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003': 0.8186840783525866, 'Loss_Exp/eval_phase/test_stream/Task000/Exp003': 0.9892196713351293, 'CPUUsage_Exp/eval_phase/test_stream/Task000/Exp003': 94.51292884364099, 'DiskUsage_Exp/eval_phase/test_stream/Task000/Exp003': 55555.4482421875, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004': 0.0, 'Loss_Exp/eval_phase/test_stream/Task000/Exp004': 3.209181608601383, 'CPUUsage_Exp/eval_phase/test_stream/Task000/Exp004': 88.60702499251464, 'DiskUsage_Exp/eval_phase/test_stream/Task000/Exp004': 55555.4482421875, 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.2215, 'Loss_Stream/eval_phase/test_stream/Task000': 2.2129494623780253, 'StreamForgetting/eval_phase/test_stream': 0.8446698608044049, 'ConfusionMatrix_Stream/eval_phase/test_stream': tensor([[   0,    0,    0,    0,  158,  513,    4,    0,    0,  305],\n",
            "        [   0,    0,    0,    0,  106,  176,    0,    0,    6,  847],\n",
            "        [   0,    0,    0,    0,  321,  316,   78,    0,    0,  317],\n",
            "        [   0,    0,    0,    0,    8,  565,    2,    0,    0,  435],\n",
            "        [   0,    0,    0,    0,  678,    0,    0,    0,    0,  304],\n",
            "        [   0,    0,    0,    0,  120,  452,    1,    0,    0,  319],\n",
            "        [   0,    0,    0,    0,  577,   65,  133,    0,    0,  183],\n",
            "        [   0,    0,    0,    0,   26,    1,    0,    0,    0, 1001],\n",
            "        [   0,    0,    0,    0,   77,  118,    0,    0,    0,  779],\n",
            "        [   0,    0,    0,    0,   55,    1,    1,    0,    0,  952]]), 'DiskUsage_Stream/eval_phase/test_stream/Task000': 55555.4482421875, 'ExperienceForgetting/eval_phase/test_stream/Task000/Exp000': 0.9422135161606269, 'ExperienceForgetting/eval_phase/test_stream/Task000/Exp001': 0.8959627329192547, 'ExperienceForgetting/eval_phase/test_stream/Task000/Exp002': 0.6958333333333333}\n"
          ]
        }
      ],
      "source": [
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QfVmw4s7_ijc",
        "outputId": "15c4bec8-10f9-4e4b-c26d-2117ccd64135",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Top1_Acc_MB/train_phase/train_stream/Task000': 0.9939393939393939, 'Loss_MB/train_phase/train_stream/Task000': 0.5233470797538757, 'DiskUsage_MB/train_phase/train_stream/Task000': 55555.4482421875, 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.42250296091591, 'Loss_Epoch/train_phase/train_stream/Task000': 1.9481726124547378, 'Time_Epoch/train_phase/train_stream/Task000': 2.7174827160000063, 'DiskUsage_Epoch/train_phase/train_stream/Task000': 55555.4482421875, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.0, 'Loss_Exp/eval_phase/test_stream/Task000/Exp000': 2.843151956300427, 'CPUUsage_Exp/eval_phase/test_stream/Task000/Exp000': 96.36418486771937, 'DiskUsage_Exp/eval_phase/test_stream/Task000/Exp000': 55555.4482421875, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.0005175983436853002, 'Loss_Exp/eval_phase/test_stream/Task000/Exp001': 2.918635980929894, 'CPUUsage_Exp/eval_phase/test_stream/Task000/Exp001': 95.93367377560546, 'DiskUsage_Exp/eval_phase/test_stream/Task000/Exp001': 55555.4482421875, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002': 0.0, 'Loss_Exp/eval_phase/test_stream/Task000/Exp002': 2.5603520597020784, 'CPUUsage_Exp/eval_phase/test_stream/Task000/Exp002': 100.72404300362618, 'DiskUsage_Exp/eval_phase/test_stream/Task000/Exp002': 55555.4482421875, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003': 0.6991461577096936, 'Loss_Exp/eval_phase/test_stream/Task000/Exp003': 1.2500105159238377, 'CPUUsage_Exp/eval_phase/test_stream/Task000/Exp003': 68.764883515404, 'DiskUsage_Exp/eval_phase/test_stream/Task000/Exp003': 55555.4482421875, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004': 0.9962174940898345, 'Loss_Exp/eval_phase/test_stream/Task000/Exp004': 0.45138369356204994, 'CPUUsage_Exp/eval_phase/test_stream/Task000/Exp004': 68.8999789238025, 'DiskUsage_Exp/eval_phase/test_stream/Task000/Exp004': 55555.4482421875, 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.35, 'Loss_Stream/eval_phase/test_stream/Task000': 1.9803844413638114, 'StreamForgetting/eval_phase/test_stream': 0.7393217877723086, 'ConfusionMatrix_Stream/eval_phase/test_stream': tensor([[ 976,    3,    0,    0,    0,    0,    0,    0,    0,    1],\n",
            "        [   4, 1131,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [ 494,  468,    0,    0,   54,    0,    5,    0,    0,   11],\n",
            "        [ 611,  329,    0,    0,    2,    1,    0,    0,    0,   67],\n",
            "        [ 106,  110,    0,    0,  723,    0,    0,    0,    0,   43],\n",
            "        [ 742,  123,    0,    0,    7,    0,    0,    0,    0,   20],\n",
            "        [ 692,  138,    0,    0,  126,    0,    1,    0,    0,    1],\n",
            "        [ 147,  155,    0,    0,   11,    0,    0,    0,    0,  715],\n",
            "        [ 475,  426,    0,    0,   14,    0,    0,    0,    0,   59],\n",
            "        [ 208,   85,    0,    0,   47,    0,    0,    0,    0,  669]]), 'DiskUsage_Stream/eval_phase/test_stream/Task000': 55555.4482421875, 'ExperienceForgetting/eval_phase/test_stream/Task000/Exp000': 0.9422135161606269, 'ExperienceForgetting/eval_phase/test_stream/Task000/Exp001': 0.9642857142857143, 'ExperienceForgetting/eval_phase/test_stream/Task000/Exp002': 0.93125, 'ExperienceForgetting/eval_phase/test_stream/Task000/Exp003': 0.11953792064289304}\n"
          ]
        }
      ],
      "source": [
        "print(results[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77WSWr_v_ijc"
      },
      "source": [
        "This completes the \"_Evaluation_\" tutorial for the \"_From Zero to Hero_\" series. We hope you enjoyed it!\n",
        "\n",
        "## ü§ù Run it on Google Colab\n",
        "\n",
        "You can run _this chapter_ and play with it on Google Colaboratory: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ContinualAI/avalanche/blob/master/notebooks/from-zero-to-hero-tutorial/05_evaluation.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1wsUJzP_ijc"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}